{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled6.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOm/1IMEqBQI9vfDYG11NWU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sandeshar/google/blob/main/gan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import pytorch_lightning as pl"
      ],
      "metadata": {
        "id": "MXIRP_iiL9Yt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "  '''\n",
        "  Generator class. Accepts a tensor of size 100 as input as outputs another\n",
        "  tensor of size 784. Objective is to generate an output tensor that is\n",
        "  indistinguishable from the real MNIST digits \n",
        "  '''\n",
        "  \n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layer1 = nn.Sequential(nn.Linear(in_features=100, out_features=256),\n",
        "                                nn.LeakyReLU())\n",
        "    self.layer2 = nn.Sequential(nn.Linear(in_features=256, out_features=512),\n",
        "                                nn.LeakyReLU())\n",
        "    self.layer3 = nn.Sequential(nn.Linear(in_features=512, out_features=1024),\n",
        "                                nn.LeakyReLU())\n",
        "    self.output = nn.Sequential(nn.Linear(in_features=1024, out_features=28*28),\n",
        "                                nn.Tanh())\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.layer1(x)\n",
        "    x = self.layer2(x)\n",
        "    x = self.layer3(x)\n",
        "    x = self.output(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "8E-ZjHgJMCRL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "  '''\n",
        "  Discriminator class. Accepts a tensor of size 784 as input and outputs\n",
        "  a tensor of size 1, with the predicted class probabilities\n",
        "  (generated or real data)\n",
        "  '''\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layer1 = nn.Sequential(nn.Linear(in_features=28*28, out_features=1024),\n",
        "                                nn.LeakyReLU())\n",
        "    self.layer2 = nn.Sequential(nn.Linear(in_features=1024, out_features=512),\n",
        "                                nn.LeakyReLU())\n",
        "    self.layer3 = nn.Sequential(nn.Linear(in_features=512, out_features=256),\n",
        "                                nn.LeakyReLU())\n",
        "    self.output = nn.Sequential(nn.Linear(in_features=256, out_features=1),\n",
        "                                nn.Sigmoid())\n",
        "    \n",
        "  def forward(self, x):\n",
        "    x = self.layer1(x)\n",
        "    x = self.layer2(x)\n",
        "    x = self.layer3(x)\n",
        "    x = self.output(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "BgfJF0RoMKMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GAN(pl.LightningModule):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.generator = Generator()\n",
        "    self.discriminator = Discriminator()\n",
        "    self.test_noises = torch.randn(100,1,100, device=device)\n",
        "    self.test_progression = []\n",
        "\n",
        "  def forward(self, z):\n",
        "    \"\"\"\n",
        "    Generates an image using the generator\n",
        "    given input noise z\n",
        "    \"\"\"\n",
        "    return self.generator(z)\n",
        "\n",
        "  def generator_step(self, x):\n",
        "    \"\"\"\n",
        "    Training step for generator\n",
        "    1. Sample random noise\n",
        "    2. Pass noise to generator to\n",
        "       generate images\n",
        "    3. Classify generated images using\n",
        "       the discriminator\n",
        "    4. Backprop loss\n",
        "    \"\"\"\n",
        "    \n",
        "    # Sample noise\n",
        "    # z = torch.randn(x.shape, device=device)\n",
        "    z = torch.randn(x.shape[0], 1, 100, device=device)\n",
        "\n",
        "    # Generate images\n",
        "    generated_imgs = self(z)\n",
        "\n",
        "    # Classify generated images\n",
        "    # using the discriminator\n",
        "    d_output = torch.squeeze(self.discriminator(generated_imgs))\n",
        "\n",
        "    # Backprop loss\n",
        "    g_loss = nn.BCELoss()(d_output, torch.ones(x.shape[0], device=device))\n",
        "\n",
        "    return g_loss\n",
        "\n",
        "  def discriminator_step(self, x):\n",
        "    \"\"\"\n",
        "    Training step for discriminator\n",
        "    1. Get actual images\n",
        "    2. Get fake images from generator\n",
        "    3. Predict probabilities of actual images\n",
        "    4. Predict probabilities of fake images\n",
        "    5. Get loss of both and backprop\n",
        "    \"\"\"\n",
        "    \n",
        "    # Real images\n",
        "    d_output = torch.squeeze(self.discriminator(x))\n",
        "    loss_real = nn.BCELoss()(d_output, torch.ones(x.shape[0], device=device))\n",
        "\n",
        "    # Fake images\n",
        "    z = torch.randn(x.shape[0], 1, 100, device=device)\n",
        "    generated_imgs = self(z)\n",
        "    d_output = torch.squeeze(self.discriminator(generated_imgs))\n",
        "    loss_fake = nn.BCELoss()(d_output, torch.zeros(x.shape[0], device=device))\n",
        "\n",
        "    return loss_real + loss_fake\n",
        "\n",
        "  def training_step(self, batch, batch_idx, optimizer_idx):\n",
        "    X, _ = batch\n",
        "\n",
        "    # train generator\n",
        "    if optimizer_idx == 0:\n",
        "      loss = self.generator_step(X)\n",
        "    \n",
        "    # train discriminator\n",
        "    if optimizer_idx == 1:\n",
        "      loss = self.discriminator_step(X)\n",
        "\n",
        "    return loss\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "    g_optimizer = torch.optim.Adam(self.generator.parameters(), lr=0.0002)\n",
        "    d_optimizer = torch.optim.Adam(self.discriminator.parameters(), lr=0.0002)\n",
        "    return [g_optimizer, d_optimizer], []\n",
        "\n",
        "  def training_epoch_end(self, training_step_outputs):\n",
        "    epoch_test_images = self(self.test_noises)\n",
        "    self.test_progression.append(epoch_test_images)"
      ],
      "metadata": {
        "id": "4PJUoaiIMSqC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "  data = torchvision.datasets.MNIST(root='../data/MNIST', download=True,\n",
        "                                    transform=transforms.Compose([transforms.ToTensor(),\n",
        "                                      transforms.Normalize(mean=[0.5], std=[0.5]),\n",
        "                                      transforms.Lambda(lambda x: x.view(-1, 784))]))\n",
        "\n",
        "  mnist_dataloader = DataLoader(data, batch_size=128, shuffle=True, num_workers=0)\n",
        "\n",
        "  model = GAN()\n",
        "\n",
        "  trainer = pl.Trainer(max_epochs=100, gpus=1 if torch.cuda.is_available() else 0, progress_bar_refresh_rate=50)\n",
        "  trainer.fit(model, mnist_dataloader)"
      ],
      "metadata": {
        "id": "0PtjP65FM4vz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}